{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # sees 32, 32, 3\n",
    "        self.conv1 = nn.Conv2d(3, 64, 11, padding=5)\n",
    "        \n",
    "        # sees 16, 16, 64\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        \n",
    "        # sees 16, 16, 128\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        \n",
    "        # will get flattened to 128\n",
    "        self.fc1 = nn.Linear(128, 10)\n",
    "    \n",
    "        # sees 16, 16, 128 -> will flatten to 128\n",
    "        self.global_max_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.max_pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # global max pool\n",
    "        x = self.global_max_pool(x)\n",
    "        \n",
    "        # flatten (remove the 1 dimensions)\n",
    "        x = torch.squeeze(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CIFAR image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network object\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer and loss function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/1000], Loss: 2.3024\n",
      "Epoch [1/50], Step [101/1000], Loss: 2.3019\n",
      "Epoch [1/50], Step [201/1000], Loss: 2.2955\n",
      "Epoch [1/50], Step [301/1000], Loss: 2.2862\n",
      "Epoch [1/50], Step [401/1000], Loss: 2.2547\n",
      "Epoch [1/50], Step [501/1000], Loss: 2.2487\n",
      "Epoch [1/50], Step [601/1000], Loss: 2.2227\n",
      "Epoch [1/50], Step [701/1000], Loss: 2.2662\n",
      "Epoch [1/50], Step [801/1000], Loss: 2.2410\n",
      "Epoch [1/50], Step [901/1000], Loss: 2.2384\n",
      "Epoch [1/50], Train Loss: 2.2574\n",
      "Epoch [1/50], Test Loss: 2.2135\n",
      "Test Accuracy: 22.69 %\n",
      "Epoch [2/50], Step [1/1000], Loss: 2.2540\n",
      "Epoch [2/50], Step [101/1000], Loss: 2.2070\n",
      "Epoch [2/50], Step [201/1000], Loss: 2.1889\n",
      "Epoch [2/50], Step [301/1000], Loss: 2.2622\n",
      "Epoch [2/50], Step [401/1000], Loss: 2.2540\n",
      "Epoch [2/50], Step [501/1000], Loss: 2.2084\n",
      "Epoch [2/50], Step [601/1000], Loss: 2.1223\n",
      "Epoch [2/50], Step [701/1000], Loss: 2.1311\n",
      "Epoch [2/50], Step [801/1000], Loss: 2.1540\n",
      "Epoch [2/50], Step [901/1000], Loss: 2.1194\n",
      "Epoch [2/50], Train Loss: 2.1824\n",
      "Epoch [2/50], Test Loss: 2.1522\n",
      "Test Accuracy: 29.97 %\n",
      "Epoch [3/50], Step [1/1000], Loss: 2.1505\n",
      "Epoch [3/50], Step [101/1000], Loss: 2.1523\n",
      "Epoch [3/50], Step [201/1000], Loss: 2.1582\n",
      "Epoch [3/50], Step [301/1000], Loss: 2.2358\n",
      "Epoch [3/50], Step [401/1000], Loss: 2.2891\n",
      "Epoch [3/50], Step [501/1000], Loss: 2.2310\n",
      "Epoch [3/50], Step [601/1000], Loss: 2.1383\n",
      "Epoch [3/50], Step [701/1000], Loss: 2.1440\n",
      "Epoch [3/50], Step [801/1000], Loss: 2.1460\n",
      "Epoch [3/50], Step [901/1000], Loss: 2.2860\n",
      "Epoch [3/50], Train Loss: 2.1526\n",
      "Epoch [3/50], Test Loss: 2.1526\n",
      "Test Accuracy: 29.88 %\n",
      "Epoch [4/50], Step [1/1000], Loss: 2.1646\n",
      "Epoch [4/50], Step [101/1000], Loss: 2.2231\n",
      "Epoch [4/50], Step [201/1000], Loss: 2.1015\n",
      "Epoch [4/50], Step [301/1000], Loss: 2.0158\n",
      "Epoch [4/50], Step [401/1000], Loss: 2.1219\n",
      "Epoch [4/50], Step [501/1000], Loss: 2.2137\n",
      "Epoch [4/50], Step [601/1000], Loss: 2.1013\n",
      "Epoch [4/50], Step [701/1000], Loss: 2.0984\n",
      "Epoch [4/50], Step [801/1000], Loss: 2.1612\n",
      "Epoch [4/50], Step [901/1000], Loss: 2.2026\n",
      "Epoch [4/50], Train Loss: 2.1378\n",
      "Epoch [4/50], Test Loss: 2.1270\n",
      "Test Accuracy: 32.74 %\n",
      "Epoch [5/50], Step [1/1000], Loss: 2.1429\n",
      "Epoch [5/50], Step [101/1000], Loss: 2.1108\n",
      "Epoch [5/50], Step [201/1000], Loss: 2.2221\n",
      "Epoch [5/50], Step [301/1000], Loss: 2.1477\n",
      "Epoch [5/50], Step [401/1000], Loss: 2.1090\n",
      "Epoch [5/50], Step [501/1000], Loss: 2.1247\n",
      "Epoch [5/50], Step [601/1000], Loss: 2.0667\n",
      "Epoch [5/50], Step [701/1000], Loss: 2.0410\n",
      "Epoch [5/50], Step [801/1000], Loss: 2.1421\n",
      "Epoch [5/50], Step [901/1000], Loss: 2.2664\n",
      "Epoch [5/50], Train Loss: 2.1269\n",
      "Epoch [5/50], Test Loss: 2.1195\n",
      "Test Accuracy: 33.32 %\n",
      "Epoch [6/50], Step [1/1000], Loss: 2.2164\n",
      "Epoch [6/50], Step [101/1000], Loss: 2.1502\n",
      "Epoch [6/50], Step [201/1000], Loss: 2.1769\n",
      "Epoch [6/50], Step [301/1000], Loss: 2.1206\n",
      "Epoch [6/50], Step [401/1000], Loss: 2.1268\n",
      "Epoch [6/50], Step [501/1000], Loss: 2.1339\n",
      "Epoch [6/50], Step [601/1000], Loss: 2.0394\n",
      "Epoch [6/50], Step [701/1000], Loss: 2.0521\n",
      "Epoch [6/50], Step [801/1000], Loss: 2.0765\n",
      "Epoch [6/50], Step [901/1000], Loss: 2.0888\n",
      "Epoch [6/50], Train Loss: 2.1143\n",
      "Epoch [6/50], Test Loss: 2.1121\n",
      "Test Accuracy: 34.07 %\n",
      "Epoch [7/50], Step [1/1000], Loss: 2.1959\n",
      "Epoch [7/50], Step [101/1000], Loss: 2.0989\n",
      "Epoch [7/50], Step [201/1000], Loss: 2.1656\n",
      "Epoch [7/50], Step [301/1000], Loss: 2.1701\n",
      "Epoch [7/50], Step [401/1000], Loss: 2.0724\n",
      "Epoch [7/50], Step [501/1000], Loss: 2.0812\n",
      "Epoch [7/50], Step [601/1000], Loss: 2.1252\n",
      "Epoch [7/50], Step [701/1000], Loss: 2.1053\n",
      "Epoch [7/50], Step [801/1000], Loss: 2.1876\n",
      "Epoch [7/50], Step [901/1000], Loss: 1.9391\n",
      "Epoch [7/50], Train Loss: 2.0996\n",
      "Epoch [7/50], Test Loss: 2.0917\n",
      "Test Accuracy: 36.56 %\n",
      "Epoch [8/50], Step [1/1000], Loss: 2.1707\n",
      "Epoch [8/50], Step [101/1000], Loss: 2.0346\n",
      "Epoch [8/50], Step [201/1000], Loss: 1.9911\n",
      "Epoch [8/50], Step [301/1000], Loss: 2.1579\n",
      "Epoch [8/50], Step [401/1000], Loss: 2.0198\n",
      "Epoch [8/50], Step [501/1000], Loss: 2.0749\n",
      "Epoch [8/50], Step [601/1000], Loss: 2.1028\n",
      "Epoch [8/50], Step [701/1000], Loss: 2.1233\n",
      "Epoch [8/50], Step [801/1000], Loss: 2.1553\n",
      "Epoch [8/50], Step [901/1000], Loss: 2.1194\n",
      "Epoch [8/50], Train Loss: 2.0724\n",
      "Epoch [8/50], Test Loss: 2.0822\n",
      "Test Accuracy: 37.67 %\n",
      "Epoch [9/50], Step [1/1000], Loss: 2.1870\n",
      "Epoch [9/50], Step [101/1000], Loss: 2.0797\n",
      "Epoch [9/50], Step [201/1000], Loss: 2.0667\n",
      "Epoch [9/50], Step [301/1000], Loss: 2.0553\n",
      "Epoch [9/50], Step [401/1000], Loss: 2.1842\n",
      "Epoch [9/50], Step [501/1000], Loss: 1.9490\n",
      "Epoch [9/50], Step [601/1000], Loss: 2.0795\n",
      "Epoch [9/50], Step [701/1000], Loss: 1.9759\n",
      "Epoch [9/50], Step [801/1000], Loss: 2.0192\n",
      "Epoch [9/50], Step [901/1000], Loss: 2.0558\n",
      "Epoch [9/50], Train Loss: 2.0533\n",
      "Epoch [9/50], Test Loss: 2.0256\n",
      "Test Accuracy: 43.34 %\n",
      "Epoch [10/50], Step [1/1000], Loss: 2.0503\n",
      "Epoch [10/50], Step [101/1000], Loss: 2.0117\n",
      "Epoch [10/50], Step [201/1000], Loss: 1.9384\n",
      "Epoch [10/50], Step [301/1000], Loss: 2.0779\n",
      "Epoch [10/50], Step [401/1000], Loss: 2.0198\n",
      "Epoch [10/50], Step [501/1000], Loss: 2.0285\n",
      "Epoch [10/50], Step [601/1000], Loss: 1.9888\n",
      "Epoch [10/50], Step [701/1000], Loss: 2.0766\n",
      "Epoch [10/50], Step [801/1000], Loss: 2.0054\n",
      "Epoch [10/50], Step [901/1000], Loss: 2.0362\n",
      "Epoch [10/50], Train Loss: 2.0392\n",
      "Epoch [10/50], Test Loss: 2.0409\n",
      "Test Accuracy: 41.57 %\n",
      "Epoch [11/50], Step [1/1000], Loss: 1.9687\n",
      "Epoch [11/50], Step [101/1000], Loss: 2.0268\n",
      "Epoch [11/50], Step [201/1000], Loss: 2.0557\n",
      "Epoch [11/50], Step [301/1000], Loss: 1.9400\n",
      "Epoch [11/50], Step [401/1000], Loss: 2.1515\n",
      "Epoch [11/50], Step [501/1000], Loss: 2.0130\n",
      "Epoch [11/50], Step [601/1000], Loss: 2.0235\n",
      "Epoch [11/50], Step [701/1000], Loss: 2.0871\n",
      "Epoch [11/50], Step [801/1000], Loss: 2.0830\n",
      "Epoch [11/50], Step [901/1000], Loss: 2.0807\n",
      "Epoch [11/50], Train Loss: 2.0269\n",
      "Epoch [11/50], Test Loss: 2.0140\n",
      "Test Accuracy: 44.31 %\n",
      "Epoch [12/50], Step [1/1000], Loss: 2.0299\n",
      "Epoch [12/50], Step [101/1000], Loss: 2.0409\n",
      "Epoch [12/50], Step [201/1000], Loss: 1.9997\n",
      "Epoch [12/50], Step [301/1000], Loss: 2.0475\n",
      "Epoch [12/50], Step [401/1000], Loss: 2.2165\n",
      "Epoch [12/50], Step [501/1000], Loss: 1.9794\n",
      "Epoch [12/50], Step [601/1000], Loss: 1.9065\n",
      "Epoch [12/50], Step [701/1000], Loss: 2.0163\n",
      "Epoch [12/50], Step [801/1000], Loss: 2.0389\n",
      "Epoch [12/50], Step [901/1000], Loss: 2.1026\n",
      "Epoch [12/50], Train Loss: 2.0164\n",
      "Epoch [12/50], Test Loss: 2.0135\n",
      "Test Accuracy: 44.31 %\n",
      "Epoch [13/50], Step [1/1000], Loss: 1.9761\n",
      "Epoch [13/50], Step [101/1000], Loss: 2.0460\n",
      "Epoch [13/50], Step [201/1000], Loss: 2.0170\n",
      "Epoch [13/50], Step [301/1000], Loss: 1.9551\n",
      "Epoch [13/50], Step [401/1000], Loss: 2.0836\n",
      "Epoch [13/50], Step [501/1000], Loss: 2.1077\n",
      "Epoch [13/50], Step [601/1000], Loss: 1.9517\n",
      "Epoch [13/50], Step [701/1000], Loss: 1.9789\n",
      "Epoch [13/50], Step [801/1000], Loss: 2.0641\n",
      "Epoch [13/50], Step [901/1000], Loss: 2.0066\n",
      "Epoch [13/50], Train Loss: 2.0082\n",
      "Epoch [13/50], Test Loss: 2.0126\n",
      "Test Accuracy: 44.22 %\n",
      "Epoch [14/50], Step [1/1000], Loss: 2.1056\n",
      "Epoch [14/50], Step [101/1000], Loss: 2.0592\n",
      "Epoch [14/50], Step [201/1000], Loss: 1.9257\n",
      "Epoch [14/50], Step [301/1000], Loss: 1.9521\n",
      "Epoch [14/50], Step [401/1000], Loss: 2.0462\n",
      "Epoch [14/50], Step [501/1000], Loss: 1.9805\n",
      "Epoch [14/50], Step [601/1000], Loss: 2.0890\n",
      "Epoch [14/50], Step [701/1000], Loss: 2.0101\n",
      "Epoch [14/50], Step [801/1000], Loss: 1.9065\n",
      "Epoch [14/50], Step [901/1000], Loss: 2.0470\n",
      "Epoch [14/50], Train Loss: 1.9983\n",
      "Epoch [14/50], Test Loss: 1.9898\n",
      "Test Accuracy: 46.95 %\n",
      "Epoch [15/50], Step [1/1000], Loss: 2.0318\n",
      "Epoch [15/50], Step [101/1000], Loss: 1.9532\n",
      "Epoch [15/50], Step [201/1000], Loss: 1.9702\n",
      "Epoch [15/50], Step [301/1000], Loss: 1.9996\n",
      "Epoch [15/50], Step [401/1000], Loss: 2.0492\n",
      "Epoch [15/50], Step [501/1000], Loss: 1.9379\n",
      "Epoch [15/50], Step [601/1000], Loss: 1.9578\n",
      "Epoch [15/50], Step [701/1000], Loss: 1.9076\n",
      "Epoch [15/50], Step [801/1000], Loss: 2.0139\n",
      "Epoch [15/50], Step [901/1000], Loss: 1.9415\n",
      "Epoch [15/50], Train Loss: 1.9902\n",
      "Epoch [15/50], Test Loss: 2.0113\n",
      "Test Accuracy: 44.52 %\n",
      "Epoch [16/50], Step [1/1000], Loss: 1.9354\n",
      "Epoch [16/50], Step [101/1000], Loss: 2.0206\n",
      "Epoch [16/50], Step [201/1000], Loss: 2.0227\n",
      "Epoch [16/50], Step [301/1000], Loss: 2.0052\n",
      "Epoch [16/50], Step [401/1000], Loss: 1.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [501/1000], Loss: 2.0039\n",
      "Epoch [16/50], Step [601/1000], Loss: 2.1101\n",
      "Epoch [16/50], Step [701/1000], Loss: 1.9825\n",
      "Epoch [16/50], Step [801/1000], Loss: 1.9100\n",
      "Epoch [16/50], Step [901/1000], Loss: 2.0027\n",
      "Epoch [16/50], Train Loss: 1.9811\n",
      "Epoch [16/50], Test Loss: 1.9804\n",
      "Test Accuracy: 47.84 %\n",
      "Epoch [17/50], Step [1/1000], Loss: 1.9438\n",
      "Epoch [17/50], Step [101/1000], Loss: 1.9675\n",
      "Epoch [17/50], Step [201/1000], Loss: 1.9535\n",
      "Epoch [17/50], Step [301/1000], Loss: 1.9960\n",
      "Epoch [17/50], Step [401/1000], Loss: 2.0680\n",
      "Epoch [17/50], Step [501/1000], Loss: 1.8842\n",
      "Epoch [17/50], Step [601/1000], Loss: 2.0697\n",
      "Epoch [17/50], Step [701/1000], Loss: 1.8581\n",
      "Epoch [17/50], Step [801/1000], Loss: 2.0632\n",
      "Epoch [17/50], Step [901/1000], Loss: 2.0320\n",
      "Epoch [17/50], Train Loss: 1.9768\n",
      "Epoch [17/50], Test Loss: 1.9816\n",
      "Test Accuracy: 47.8 %\n",
      "Epoch [18/50], Step [1/1000], Loss: 1.8546\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "epochs = 50\n",
    "total_steps = len(trainloader)\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# loop through epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_running_loss = 0  # track train running loss\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # load batch images/labels\n",
    "    for step, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        # put data onto available device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = model(images)  # forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)  # retrieve top preds\n",
    "        \n",
    "        total += labels.size(0)  # add batch size\n",
    "        correct += (predicted == labels).sum().item()  # calc num correct\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # calc loss\n",
    "        train_running_loss += loss.item()  # acc running loss\n",
    "        \n",
    "        loss.backward()   # backprop\n",
    "        optimizer.step()  # forward\n",
    "\n",
    "        if step % 100 == 0:  # print progress by iteration\n",
    "        \n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "            .format(epoch+1, epochs, step+1, total_steps, loss.item()))\n",
    "    \n",
    "    # div by num batches to get average\n",
    "    epoch_train_loss = train_running_loss / len(trainloader)\n",
    "                   \n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, epochs, epoch_train_loss))\n",
    "        \n",
    "    # append the loss/acc after all the steps \n",
    "    training_losses.append(epoch_train_loss)\n",
    "    train_acc.append(correct / total)\n",
    "        \n",
    "    \n",
    "    # ------------------------------ #\n",
    "    \n",
    "\n",
    "    # evaluate on test data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_running_loss = 0  # track test running loss\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in testloader:\n",
    "                   \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "                   \n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()\n",
    "                   \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "                 \n",
    "    # div by num batches\n",
    "    epoch_test_loss = test_running_loss / len(testloader)\n",
    "                   \n",
    "    print('Epoch [{}/{}], Test Loss: {:.4f}'.format(epoch+1, epochs, epoch_test_loss))\n",
    "        \n",
    "    # append the loss & acc after all the steps \n",
    "    test_losses.append(epoch_test_loss)\n",
    "    test_acc.append(correct / total)\n",
    "            \n",
    "    print('Test Accuracy: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(train_losses, test_losses, train_acc, test_acc):\n",
    "    # plot graph\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Train loss\")\n",
    "    plt.plot(test_losses, label=\"Test loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss (Cross entropy)\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "    plt.plot(test_acc, label=\"Test Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Accuracy vs Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(training_losses, test_losses, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
