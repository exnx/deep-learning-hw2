{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # sees 32, 32, 3\n",
    "        self.conv1 = nn.Conv2d(3, 64, 11, padding=5)\n",
    "        \n",
    "        # sees 16, 16, 64\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        \n",
    "        # sees 16, 16, 128\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        \n",
    "        # will get flattened to 128\n",
    "        self.fc1 = nn.Linear(128, 10)\n",
    "    \n",
    "        # sees 16, 16, 128 -> will flatten to 128\n",
    "        self.global_max_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.max_pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # global max pool\n",
    "        x = self.global_max_pool(x)\n",
    "        \n",
    "        # flatten (remove the 1 dimensions)\n",
    "        x = torch.squeeze(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CIFAR image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network object\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer and loss function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/1000], Loss: 2.3025\n",
      "Epoch [1/50], Step [101/1000], Loss: 2.3021\n",
      "Epoch [1/50], Step [201/1000], Loss: 2.2974\n",
      "Epoch [1/50], Step [301/1000], Loss: 2.2887\n",
      "Epoch [1/50], Step [401/1000], Loss: 2.2858\n",
      "Epoch [1/50], Step [501/1000], Loss: 2.2606\n",
      "Epoch [1/50], Step [601/1000], Loss: 2.2419\n",
      "Epoch [1/50], Step [701/1000], Loss: 2.2449\n",
      "Epoch [1/50], Step [801/1000], Loss: 2.2076\n",
      "Epoch [1/50], Step [901/1000], Loss: 2.2101\n",
      "Epoch [1/50], Train Loss: 2.2685\n",
      "Epoch [1/50], Test Loss: 2.2231\n",
      "Test Accuracy: 22.71 %\n",
      "Epoch [2/50], Step [1/1000], Loss: 2.1746\n",
      "Epoch [2/50], Step [101/1000], Loss: 2.1429\n",
      "Epoch [2/50], Step [201/1000], Loss: 2.2489\n",
      "Epoch [2/50], Step [301/1000], Loss: 2.1482\n",
      "Epoch [2/50], Step [401/1000], Loss: 2.2966\n",
      "Epoch [2/50], Step [501/1000], Loss: 2.2128\n",
      "Epoch [2/50], Step [601/1000], Loss: 2.1003\n",
      "Epoch [2/50], Step [701/1000], Loss: 2.1078\n",
      "Epoch [2/50], Step [801/1000], Loss: 2.1105\n",
      "Epoch [2/50], Step [901/1000], Loss: 2.1336\n",
      "Epoch [2/50], Train Loss: 2.1970\n",
      "Epoch [2/50], Test Loss: 2.1842\n",
      "Test Accuracy: 26.92 %\n",
      "Epoch [3/50], Step [1/1000], Loss: 2.2013\n",
      "Epoch [3/50], Step [101/1000], Loss: 2.1564\n",
      "Epoch [3/50], Step [201/1000], Loss: 2.1287\n",
      "Epoch [3/50], Step [301/1000], Loss: 2.1098\n",
      "Epoch [3/50], Step [401/1000], Loss: 2.1365\n",
      "Epoch [3/50], Step [501/1000], Loss: 2.1677\n",
      "Epoch [3/50], Step [601/1000], Loss: 2.0988\n",
      "Epoch [3/50], Step [701/1000], Loss: 2.1583\n",
      "Epoch [3/50], Step [801/1000], Loss: 2.2024\n",
      "Epoch [3/50], Step [901/1000], Loss: 2.1145\n",
      "Epoch [3/50], Train Loss: 2.1714\n",
      "Epoch [3/50], Test Loss: 2.1576\n",
      "Test Accuracy: 29.56 %\n",
      "Epoch [4/50], Step [1/1000], Loss: 2.1692\n",
      "Epoch [4/50], Step [101/1000], Loss: 2.1569\n",
      "Epoch [4/50], Step [201/1000], Loss: 2.1187\n",
      "Epoch [4/50], Step [301/1000], Loss: 2.1034\n",
      "Epoch [4/50], Step [401/1000], Loss: 2.1312\n",
      "Epoch [4/50], Step [501/1000], Loss: 2.1569\n",
      "Epoch [4/50], Step [601/1000], Loss: 2.1384\n",
      "Epoch [4/50], Step [701/1000], Loss: 2.1353\n",
      "Epoch [4/50], Step [801/1000], Loss: 2.1934\n",
      "Epoch [4/50], Step [901/1000], Loss: 2.2191\n",
      "Epoch [4/50], Train Loss: 2.1578\n",
      "Epoch [4/50], Test Loss: 2.1520\n",
      "Test Accuracy: 30.23 %\n",
      "Epoch [5/50], Step [1/1000], Loss: 2.2671\n",
      "Epoch [5/50], Step [101/1000], Loss: 2.1242\n",
      "Epoch [5/50], Step [201/1000], Loss: 2.0366\n",
      "Epoch [5/50], Step [301/1000], Loss: 2.2145\n",
      "Epoch [5/50], Step [401/1000], Loss: 2.1765\n",
      "Epoch [5/50], Step [501/1000], Loss: 2.2149\n",
      "Epoch [5/50], Step [601/1000], Loss: 2.0849\n",
      "Epoch [5/50], Step [701/1000], Loss: 2.1483\n",
      "Epoch [5/50], Step [801/1000], Loss: 2.1618\n",
      "Epoch [5/50], Step [901/1000], Loss: 2.1747\n",
      "Epoch [5/50], Train Loss: 2.1455\n",
      "Epoch [5/50], Test Loss: 2.1371\n",
      "Test Accuracy: 31.93 %\n",
      "Epoch [6/50], Step [1/1000], Loss: 2.0616\n",
      "Epoch [6/50], Step [101/1000], Loss: 2.2176\n",
      "Epoch [6/50], Step [201/1000], Loss: 2.1521\n",
      "Epoch [6/50], Step [301/1000], Loss: 2.1389\n",
      "Epoch [6/50], Step [401/1000], Loss: 2.1432\n",
      "Epoch [6/50], Step [501/1000], Loss: 2.1433\n",
      "Epoch [6/50], Step [601/1000], Loss: 2.1688\n",
      "Epoch [6/50], Step [701/1000], Loss: 2.2313\n",
      "Epoch [6/50], Step [801/1000], Loss: 2.1478\n",
      "Epoch [6/50], Step [901/1000], Loss: 2.0825\n",
      "Epoch [6/50], Train Loss: 2.1330\n",
      "Epoch [6/50], Test Loss: 2.1237\n",
      "Test Accuracy: 33.46 %\n",
      "Epoch [7/50], Step [1/1000], Loss: 2.0379\n",
      "Epoch [7/50], Step [101/1000], Loss: 2.0790\n",
      "Epoch [7/50], Step [201/1000], Loss: 2.1073\n",
      "Epoch [7/50], Step [301/1000], Loss: 2.0978\n",
      "Epoch [7/50], Step [401/1000], Loss: 2.0779\n",
      "Epoch [7/50], Step [501/1000], Loss: 2.1352\n",
      "Epoch [7/50], Step [601/1000], Loss: 2.0342\n",
      "Epoch [7/50], Step [701/1000], Loss: 2.1579\n",
      "Epoch [7/50], Step [801/1000], Loss: 2.1604\n",
      "Epoch [7/50], Step [901/1000], Loss: 2.0288\n",
      "Epoch [7/50], Train Loss: 2.1217\n",
      "Epoch [7/50], Test Loss: 2.1259\n",
      "Test Accuracy: 33.34 %\n",
      "Epoch [8/50], Step [1/1000], Loss: 2.2042\n",
      "Epoch [8/50], Step [101/1000], Loss: 2.0871\n",
      "Epoch [8/50], Step [201/1000], Loss: 2.0902\n",
      "Epoch [8/50], Step [301/1000], Loss: 2.1902\n",
      "Epoch [8/50], Step [401/1000], Loss: 2.1787\n",
      "Epoch [8/50], Step [501/1000], Loss: 2.1288\n",
      "Epoch [8/50], Step [601/1000], Loss: 2.1251\n",
      "Epoch [8/50], Step [701/1000], Loss: 2.1289\n",
      "Epoch [8/50], Step [801/1000], Loss: 2.1601\n",
      "Epoch [8/50], Step [901/1000], Loss: 2.0205\n",
      "Epoch [8/50], Train Loss: 2.1147\n",
      "Epoch [8/50], Test Loss: 2.1083\n",
      "Test Accuracy: 34.95 %\n",
      "Epoch [9/50], Step [1/1000], Loss: 2.0401\n",
      "Epoch [9/50], Step [101/1000], Loss: 2.1825\n",
      "Epoch [9/50], Step [201/1000], Loss: 2.0187\n",
      "Epoch [9/50], Step [301/1000], Loss: 2.0712\n",
      "Epoch [9/50], Step [401/1000], Loss: 2.0866\n",
      "Epoch [9/50], Step [501/1000], Loss: 2.1145\n",
      "Epoch [9/50], Step [601/1000], Loss: 2.0484\n",
      "Epoch [9/50], Step [701/1000], Loss: 2.0704\n",
      "Epoch [9/50], Step [801/1000], Loss: 2.1249\n",
      "Epoch [9/50], Step [901/1000], Loss: 2.1547\n",
      "Epoch [9/50], Train Loss: 2.1062\n",
      "Epoch [9/50], Test Loss: 2.1078\n",
      "Test Accuracy: 34.94 %\n",
      "Epoch [10/50], Step [1/1000], Loss: 2.0052\n",
      "Epoch [10/50], Step [101/1000], Loss: 2.1854\n",
      "Epoch [10/50], Step [201/1000], Loss: 2.1958\n",
      "Epoch [10/50], Step [301/1000], Loss: 2.2633\n",
      "Epoch [10/50], Step [401/1000], Loss: 2.0582\n",
      "Epoch [10/50], Step [501/1000], Loss: 2.0793\n",
      "Epoch [10/50], Step [601/1000], Loss: 2.0019\n",
      "Epoch [10/50], Step [701/1000], Loss: 2.0776\n",
      "Epoch [10/50], Step [801/1000], Loss: 2.1415\n",
      "Epoch [10/50], Step [901/1000], Loss: 2.0753\n",
      "Epoch [10/50], Train Loss: 2.0975\n",
      "Epoch [10/50], Test Loss: 2.1038\n",
      "Test Accuracy: 35.23 %\n",
      "Epoch [11/50], Step [1/1000], Loss: 2.0309\n",
      "Epoch [11/50], Step [101/1000], Loss: 2.0693\n",
      "Epoch [11/50], Step [201/1000], Loss: 2.0490\n",
      "Epoch [11/50], Step [301/1000], Loss: 2.1192\n",
      "Epoch [11/50], Step [401/1000], Loss: 2.0531\n",
      "Epoch [11/50], Step [501/1000], Loss: 2.0524\n",
      "Epoch [11/50], Step [601/1000], Loss: 2.2130\n",
      "Epoch [11/50], Step [701/1000], Loss: 2.1126\n",
      "Epoch [11/50], Step [801/1000], Loss: 2.1477\n",
      "Epoch [11/50], Step [901/1000], Loss: 2.0203\n",
      "Epoch [11/50], Train Loss: 2.0963\n",
      "Epoch [11/50], Test Loss: 2.1163\n",
      "Test Accuracy: 34.2 %\n",
      "Epoch [12/50], Step [1/1000], Loss: 2.1697\n",
      "Epoch [12/50], Step [101/1000], Loss: 2.1913\n",
      "Epoch [12/50], Step [201/1000], Loss: 2.0795\n",
      "Epoch [12/50], Step [301/1000], Loss: 2.0446\n",
      "Epoch [12/50], Step [401/1000], Loss: 2.0716\n",
      "Epoch [12/50], Step [501/1000], Loss: 2.2887\n",
      "Epoch [12/50], Step [601/1000], Loss: 2.0035\n",
      "Epoch [12/50], Step [701/1000], Loss: 2.0719\n",
      "Epoch [12/50], Step [801/1000], Loss: 2.0414\n",
      "Epoch [12/50], Step [901/1000], Loss: 2.1455\n",
      "Epoch [12/50], Train Loss: 2.0880\n",
      "Epoch [12/50], Test Loss: 2.0729\n",
      "Test Accuracy: 38.53 %\n",
      "Epoch [13/50], Step [1/1000], Loss: 2.1462\n",
      "Epoch [13/50], Step [101/1000], Loss: 2.0901\n",
      "Epoch [13/50], Step [201/1000], Loss: 2.0578\n",
      "Epoch [13/50], Step [301/1000], Loss: 2.1328\n",
      "Epoch [13/50], Step [401/1000], Loss: 2.0748\n",
      "Epoch [13/50], Step [501/1000], Loss: 2.1534\n",
      "Epoch [13/50], Step [601/1000], Loss: 2.1982\n",
      "Epoch [13/50], Step [701/1000], Loss: 2.0382\n",
      "Epoch [13/50], Step [801/1000], Loss: 2.0768\n",
      "Epoch [13/50], Step [901/1000], Loss: 2.0747\n",
      "Epoch [13/50], Train Loss: 2.0828\n",
      "Epoch [13/50], Test Loss: 2.0848\n",
      "Test Accuracy: 37.22 %\n",
      "Epoch [14/50], Step [1/1000], Loss: 2.0823\n",
      "Epoch [14/50], Step [101/1000], Loss: 2.0911\n",
      "Epoch [14/50], Step [201/1000], Loss: 2.0825\n",
      "Epoch [14/50], Step [301/1000], Loss: 2.0797\n",
      "Epoch [14/50], Step [401/1000], Loss: 2.0703\n",
      "Epoch [14/50], Step [501/1000], Loss: 2.0187\n",
      "Epoch [14/50], Step [601/1000], Loss: 2.1568\n",
      "Epoch [14/50], Step [701/1000], Loss: 2.1202\n",
      "Epoch [14/50], Step [801/1000], Loss: 2.1315\n",
      "Epoch [14/50], Step [901/1000], Loss: 1.9872\n",
      "Epoch [14/50], Train Loss: 2.0783\n",
      "Epoch [14/50], Test Loss: 2.0810\n",
      "Test Accuracy: 37.64 %\n",
      "Epoch [15/50], Step [1/1000], Loss: 2.2092\n",
      "Epoch [15/50], Step [101/1000], Loss: 2.0754\n",
      "Epoch [15/50], Step [201/1000], Loss: 2.1068\n",
      "Epoch [15/50], Step [301/1000], Loss: 2.0890\n",
      "Epoch [15/50], Step [401/1000], Loss: 2.0388\n",
      "Epoch [15/50], Step [501/1000], Loss: 2.0841\n",
      "Epoch [15/50], Step [601/1000], Loss: 2.1018\n",
      "Epoch [15/50], Step [701/1000], Loss: 2.1269\n",
      "Epoch [15/50], Step [801/1000], Loss: 2.1247\n",
      "Epoch [15/50], Step [901/1000], Loss: 2.1088\n",
      "Epoch [15/50], Train Loss: 2.0784\n",
      "Epoch [15/50], Test Loss: 2.0702\n",
      "Test Accuracy: 38.62 %\n",
      "Epoch [16/50], Step [1/1000], Loss: 1.9817\n",
      "Epoch [16/50], Step [101/1000], Loss: 2.0403\n",
      "Epoch [16/50], Step [201/1000], Loss: 2.1617\n",
      "Epoch [16/50], Step [301/1000], Loss: 2.1087\n",
      "Epoch [16/50], Step [401/1000], Loss: 2.1166\n",
      "Epoch [16/50], Step [501/1000], Loss: 1.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [601/1000], Loss: 1.9589\n",
      "Epoch [16/50], Step [701/1000], Loss: 2.0670\n",
      "Epoch [16/50], Step [801/1000], Loss: 2.0310\n",
      "Epoch [16/50], Step [901/1000], Loss: 2.1197\n",
      "Epoch [16/50], Train Loss: 2.0703\n",
      "Epoch [16/50], Test Loss: 2.0704\n",
      "Test Accuracy: 38.84 %\n",
      "Epoch [17/50], Step [1/1000], Loss: 2.0724\n",
      "Epoch [17/50], Step [101/1000], Loss: 2.0301\n",
      "Epoch [17/50], Step [201/1000], Loss: 2.0678\n",
      "Epoch [17/50], Step [301/1000], Loss: 2.1270\n",
      "Epoch [17/50], Step [401/1000], Loss: 2.0581\n",
      "Epoch [17/50], Step [501/1000], Loss: 2.0566\n",
      "Epoch [17/50], Step [601/1000], Loss: 2.0432\n",
      "Epoch [17/50], Step [701/1000], Loss: 2.0323\n",
      "Epoch [17/50], Step [801/1000], Loss: 2.0397\n",
      "Epoch [17/50], Step [901/1000], Loss: 2.1261\n",
      "Epoch [17/50], Train Loss: 2.0678\n",
      "Epoch [17/50], Test Loss: 2.0610\n",
      "Test Accuracy: 39.57 %\n",
      "Epoch [18/50], Step [1/1000], Loss: 2.0525\n",
      "Epoch [18/50], Step [101/1000], Loss: 1.9856\n",
      "Epoch [18/50], Step [201/1000], Loss: 1.9050\n",
      "Epoch [18/50], Step [301/1000], Loss: 2.0569\n",
      "Epoch [18/50], Step [401/1000], Loss: 1.9120\n",
      "Epoch [18/50], Step [501/1000], Loss: 2.0289\n",
      "Epoch [18/50], Step [601/1000], Loss: 2.0819\n",
      "Epoch [18/50], Step [701/1000], Loss: 2.0179\n",
      "Epoch [18/50], Step [801/1000], Loss: 2.0994\n",
      "Epoch [18/50], Step [901/1000], Loss: 2.1131\n",
      "Epoch [18/50], Train Loss: 2.0626\n",
      "Epoch [18/50], Test Loss: 2.0630\n",
      "Test Accuracy: 39.33 %\n",
      "Epoch [19/50], Step [1/1000], Loss: 2.0164\n",
      "Epoch [19/50], Step [101/1000], Loss: 2.0306\n",
      "Epoch [19/50], Step [201/1000], Loss: 2.1264\n",
      "Epoch [19/50], Step [301/1000], Loss: 2.0059\n",
      "Epoch [19/50], Step [401/1000], Loss: 2.1408\n",
      "Epoch [19/50], Step [501/1000], Loss: 2.0646\n",
      "Epoch [19/50], Step [601/1000], Loss: 2.0079\n",
      "Epoch [19/50], Step [701/1000], Loss: 2.0275\n",
      "Epoch [19/50], Step [801/1000], Loss: 2.0601\n",
      "Epoch [19/50], Step [901/1000], Loss: 2.0957\n",
      "Epoch [19/50], Train Loss: 2.0606\n",
      "Epoch [19/50], Test Loss: 2.0711\n",
      "Test Accuracy: 38.52 %\n",
      "Epoch [20/50], Step [1/1000], Loss: 2.0326\n",
      "Epoch [20/50], Step [101/1000], Loss: 2.1293\n",
      "Epoch [20/50], Step [201/1000], Loss: 2.1079\n",
      "Epoch [20/50], Step [301/1000], Loss: 2.0469\n",
      "Epoch [20/50], Step [401/1000], Loss: 2.0273\n",
      "Epoch [20/50], Step [501/1000], Loss: 2.1385\n",
      "Epoch [20/50], Step [601/1000], Loss: 2.1395\n",
      "Epoch [20/50], Step [701/1000], Loss: 2.1444\n",
      "Epoch [20/50], Step [801/1000], Loss: 1.9849\n",
      "Epoch [20/50], Step [901/1000], Loss: 2.0542\n",
      "Epoch [20/50], Train Loss: 2.0554\n",
      "Epoch [20/50], Test Loss: 2.0585\n",
      "Test Accuracy: 39.94 %\n",
      "Epoch [21/50], Step [1/1000], Loss: 2.1851\n",
      "Epoch [21/50], Step [101/1000], Loss: 2.1237\n",
      "Epoch [21/50], Step [201/1000], Loss: 2.0805\n",
      "Epoch [21/50], Step [301/1000], Loss: 2.1560\n",
      "Epoch [21/50], Step [401/1000], Loss: 2.0192\n",
      "Epoch [21/50], Step [501/1000], Loss: 2.1006\n",
      "Epoch [21/50], Step [601/1000], Loss: 2.1535\n",
      "Epoch [21/50], Step [701/1000], Loss: 2.0035\n",
      "Epoch [21/50], Step [801/1000], Loss: 2.0721\n",
      "Epoch [21/50], Step [901/1000], Loss: 1.9796\n",
      "Epoch [21/50], Train Loss: 2.0552\n",
      "Epoch [21/50], Test Loss: 2.0632\n",
      "Test Accuracy: 39.41 %\n",
      "Epoch [22/50], Step [1/1000], Loss: 1.9794\n",
      "Epoch [22/50], Step [101/1000], Loss: 2.0590\n",
      "Epoch [22/50], Step [201/1000], Loss: 2.1641\n",
      "Epoch [22/50], Step [301/1000], Loss: 2.1043\n",
      "Epoch [22/50], Step [401/1000], Loss: 2.1765\n",
      "Epoch [22/50], Step [501/1000], Loss: 1.9648\n",
      "Epoch [22/50], Step [601/1000], Loss: 2.1288\n",
      "Epoch [22/50], Step [701/1000], Loss: 1.8608\n",
      "Epoch [22/50], Step [801/1000], Loss: 2.0023\n",
      "Epoch [22/50], Step [901/1000], Loss: 2.0709\n",
      "Epoch [22/50], Train Loss: 2.0506\n",
      "Epoch [22/50], Test Loss: 2.0530\n",
      "Test Accuracy: 40.29 %\n",
      "Epoch [23/50], Step [1/1000], Loss: 2.0373\n",
      "Epoch [23/50], Step [101/1000], Loss: 2.0717\n",
      "Epoch [23/50], Step [201/1000], Loss: 2.0242\n",
      "Epoch [23/50], Step [301/1000], Loss: 2.0173\n",
      "Epoch [23/50], Step [401/1000], Loss: 2.0745\n",
      "Epoch [23/50], Step [501/1000], Loss: 2.0624\n",
      "Epoch [23/50], Step [601/1000], Loss: 2.0563\n",
      "Epoch [23/50], Step [701/1000], Loss: 2.1368\n",
      "Epoch [23/50], Step [801/1000], Loss: 2.0608\n",
      "Epoch [23/50], Step [901/1000], Loss: 2.0323\n",
      "Epoch [23/50], Train Loss: 2.0483\n",
      "Epoch [23/50], Test Loss: 2.0555\n",
      "Test Accuracy: 40.09 %\n",
      "Epoch [24/50], Step [1/1000], Loss: 2.0197\n",
      "Epoch [24/50], Step [101/1000], Loss: 2.1090\n",
      "Epoch [24/50], Step [201/1000], Loss: 1.9627\n",
      "Epoch [24/50], Step [301/1000], Loss: 2.0818\n",
      "Epoch [24/50], Step [401/1000], Loss: 1.9681\n",
      "Epoch [24/50], Step [501/1000], Loss: 2.0583\n",
      "Epoch [24/50], Step [601/1000], Loss: 2.0200\n",
      "Epoch [24/50], Step [701/1000], Loss: 2.0858\n",
      "Epoch [24/50], Step [801/1000], Loss: 2.0613\n",
      "Epoch [24/50], Step [901/1000], Loss: 2.0583\n",
      "Epoch [24/50], Train Loss: 2.0452\n",
      "Epoch [24/50], Test Loss: 2.0522\n",
      "Test Accuracy: 40.61 %\n",
      "Epoch [25/50], Step [1/1000], Loss: 2.0834\n",
      "Epoch [25/50], Step [101/1000], Loss: 1.9746\n",
      "Epoch [25/50], Step [201/1000], Loss: 2.0026\n",
      "Epoch [25/50], Step [301/1000], Loss: 2.0397\n",
      "Epoch [25/50], Step [401/1000], Loss: 2.1074\n",
      "Epoch [25/50], Step [501/1000], Loss: 1.9891\n",
      "Epoch [25/50], Step [601/1000], Loss: 2.0438\n",
      "Epoch [25/50], Step [701/1000], Loss: 2.1126\n",
      "Epoch [25/50], Step [801/1000], Loss: 2.0536\n",
      "Epoch [25/50], Step [901/1000], Loss: 2.0917\n",
      "Epoch [25/50], Train Loss: 2.0417\n",
      "Epoch [25/50], Test Loss: 2.0419\n",
      "Test Accuracy: 41.39 %\n",
      "Epoch [26/50], Step [1/1000], Loss: 1.9870\n",
      "Epoch [26/50], Step [101/1000], Loss: 2.1022\n",
      "Epoch [26/50], Step [201/1000], Loss: 2.0805\n",
      "Epoch [26/50], Step [301/1000], Loss: 1.9899\n",
      "Epoch [26/50], Step [401/1000], Loss: 2.1323\n",
      "Epoch [26/50], Step [501/1000], Loss: 2.0054\n",
      "Epoch [26/50], Step [601/1000], Loss: 2.1305\n",
      "Epoch [26/50], Step [701/1000], Loss: 2.0753\n",
      "Epoch [26/50], Step [801/1000], Loss: 2.0171\n",
      "Epoch [26/50], Step [901/1000], Loss: 2.0470\n",
      "Epoch [26/50], Train Loss: 2.0398\n",
      "Epoch [26/50], Test Loss: 2.0458\n",
      "Test Accuracy: 41.21 %\n",
      "Epoch [27/50], Step [1/1000], Loss: 2.0623\n",
      "Epoch [27/50], Step [101/1000], Loss: 2.0778\n",
      "Epoch [27/50], Step [201/1000], Loss: 2.1930\n",
      "Epoch [27/50], Step [301/1000], Loss: 2.0485\n",
      "Epoch [27/50], Step [401/1000], Loss: 2.0464\n",
      "Epoch [27/50], Step [501/1000], Loss: 2.0267\n",
      "Epoch [27/50], Step [601/1000], Loss: 1.9685\n",
      "Epoch [27/50], Step [701/1000], Loss: 1.9964\n",
      "Epoch [27/50], Step [801/1000], Loss: 1.9836\n",
      "Epoch [27/50], Step [901/1000], Loss: 2.0927\n",
      "Epoch [27/50], Train Loss: 2.0367\n",
      "Epoch [27/50], Test Loss: 2.0445\n",
      "Test Accuracy: 41.17 %\n",
      "Epoch [28/50], Step [1/1000], Loss: 1.9909\n",
      "Epoch [28/50], Step [101/1000], Loss: 1.9921\n",
      "Epoch [28/50], Step [201/1000], Loss: 1.9772\n",
      "Epoch [28/50], Step [301/1000], Loss: 2.0961\n",
      "Epoch [28/50], Step [401/1000], Loss: 1.9948\n",
      "Epoch [28/50], Step [501/1000], Loss: 2.0150\n",
      "Epoch [28/50], Step [601/1000], Loss: 2.1997\n",
      "Epoch [28/50], Step [701/1000], Loss: 2.0993\n",
      "Epoch [28/50], Step [801/1000], Loss: 2.1819\n",
      "Epoch [28/50], Step [901/1000], Loss: 2.1384\n",
      "Epoch [28/50], Train Loss: 2.0350\n",
      "Epoch [28/50], Test Loss: 2.0422\n",
      "Test Accuracy: 41.62 %\n",
      "Epoch [29/50], Step [1/1000], Loss: 2.0376\n",
      "Epoch [29/50], Step [101/1000], Loss: 2.0830\n",
      "Epoch [29/50], Step [201/1000], Loss: 1.9976\n",
      "Epoch [29/50], Step [301/1000], Loss: 2.0247\n",
      "Epoch [29/50], Step [401/1000], Loss: 2.0769\n",
      "Epoch [29/50], Step [501/1000], Loss: 2.0148\n",
      "Epoch [29/50], Step [601/1000], Loss: 2.1151\n",
      "Epoch [29/50], Step [701/1000], Loss: 2.0387\n",
      "Epoch [29/50], Step [801/1000], Loss: 2.0756\n",
      "Epoch [29/50], Step [901/1000], Loss: 2.0197\n",
      "Epoch [29/50], Train Loss: 2.0339\n",
      "Epoch [29/50], Test Loss: 2.0347\n",
      "Test Accuracy: 42.28 %\n",
      "Epoch [30/50], Step [1/1000], Loss: 1.9259\n",
      "Epoch [30/50], Step [101/1000], Loss: 2.0701\n",
      "Epoch [30/50], Step [201/1000], Loss: 1.9977\n",
      "Epoch [30/50], Step [301/1000], Loss: 2.0680\n",
      "Epoch [30/50], Step [401/1000], Loss: 2.0265\n",
      "Epoch [30/50], Step [501/1000], Loss: 2.0628\n",
      "Epoch [30/50], Step [601/1000], Loss: 1.9990\n",
      "Epoch [30/50], Step [701/1000], Loss: 1.8874\n",
      "Epoch [30/50], Step [801/1000], Loss: 2.0639\n",
      "Epoch [30/50], Step [901/1000], Loss: 2.0552\n",
      "Epoch [30/50], Train Loss: 2.0302\n",
      "Epoch [30/50], Test Loss: 2.0329\n",
      "Test Accuracy: 42.49 %\n",
      "Epoch [31/50], Step [1/1000], Loss: 2.1244\n",
      "Epoch [31/50], Step [101/1000], Loss: 1.9750\n",
      "Epoch [31/50], Step [201/1000], Loss: 1.9996\n",
      "Epoch [31/50], Step [301/1000], Loss: 2.0606\n",
      "Epoch [31/50], Step [401/1000], Loss: 2.0642\n",
      "Epoch [31/50], Step [501/1000], Loss: 2.0585\n",
      "Epoch [31/50], Step [601/1000], Loss: 2.0626\n",
      "Epoch [31/50], Step [701/1000], Loss: 1.9969\n",
      "Epoch [31/50], Step [801/1000], Loss: 2.0768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [901/1000], Loss: 1.9974\n",
      "Epoch [31/50], Train Loss: 2.0290\n",
      "Epoch [31/50], Test Loss: 2.0413\n",
      "Test Accuracy: 41.72 %\n",
      "Epoch [32/50], Step [1/1000], Loss: 1.9367\n",
      "Epoch [32/50], Step [101/1000], Loss: 1.9848\n",
      "Epoch [32/50], Step [201/1000], Loss: 1.9976\n",
      "Epoch [32/50], Step [301/1000], Loss: 2.0475\n",
      "Epoch [32/50], Step [401/1000], Loss: 1.9592\n",
      "Epoch [32/50], Step [501/1000], Loss: 2.0033\n",
      "Epoch [32/50], Step [601/1000], Loss: 2.1044\n",
      "Epoch [32/50], Step [701/1000], Loss: 1.9680\n",
      "Epoch [32/50], Step [801/1000], Loss: 2.0690\n",
      "Epoch [32/50], Step [901/1000], Loss: 2.1010\n",
      "Epoch [32/50], Train Loss: 2.0261\n",
      "Epoch [32/50], Test Loss: 2.0319\n",
      "Test Accuracy: 42.79 %\n",
      "Epoch [33/50], Step [1/1000], Loss: 2.0535\n",
      "Epoch [33/50], Step [101/1000], Loss: 2.1365\n",
      "Epoch [33/50], Step [201/1000], Loss: 1.9817\n",
      "Epoch [33/50], Step [301/1000], Loss: 2.0222\n",
      "Epoch [33/50], Step [401/1000], Loss: 2.0820\n",
      "Epoch [33/50], Step [501/1000], Loss: 2.0703\n",
      "Epoch [33/50], Step [601/1000], Loss: 2.0515\n",
      "Epoch [33/50], Step [701/1000], Loss: 2.0940\n",
      "Epoch [33/50], Step [801/1000], Loss: 1.9258\n",
      "Epoch [33/50], Step [901/1000], Loss: 1.9920\n",
      "Epoch [33/50], Train Loss: 2.0232\n",
      "Epoch [33/50], Test Loss: 2.0304\n",
      "Test Accuracy: 42.67 %\n",
      "Epoch [34/50], Step [1/1000], Loss: 1.9774\n",
      "Epoch [34/50], Step [101/1000], Loss: 2.0980\n",
      "Epoch [34/50], Step [201/1000], Loss: 1.9244\n",
      "Epoch [34/50], Step [301/1000], Loss: 2.0664\n",
      "Epoch [34/50], Step [401/1000], Loss: 2.0762\n",
      "Epoch [34/50], Step [501/1000], Loss: 1.9533\n",
      "Epoch [34/50], Step [601/1000], Loss: 2.0051\n",
      "Epoch [34/50], Step [701/1000], Loss: 2.0980\n",
      "Epoch [34/50], Step [801/1000], Loss: 2.0764\n",
      "Epoch [34/50], Step [901/1000], Loss: 1.9796\n",
      "Epoch [34/50], Train Loss: 2.0225\n",
      "Epoch [34/50], Test Loss: 2.0286\n",
      "Test Accuracy: 42.99 %\n",
      "Epoch [35/50], Step [1/1000], Loss: 2.1770\n",
      "Epoch [35/50], Step [101/1000], Loss: 2.0961\n",
      "Epoch [35/50], Step [201/1000], Loss: 1.9048\n",
      "Epoch [35/50], Step [301/1000], Loss: 1.9554\n",
      "Epoch [35/50], Step [401/1000], Loss: 2.0404\n",
      "Epoch [35/50], Step [501/1000], Loss: 2.0162\n",
      "Epoch [35/50], Step [601/1000], Loss: 1.8971\n",
      "Epoch [35/50], Step [701/1000], Loss: 1.9556\n",
      "Epoch [35/50], Step [801/1000], Loss: 2.0203\n",
      "Epoch [35/50], Step [901/1000], Loss: 2.0748\n",
      "Epoch [35/50], Train Loss: 2.0191\n",
      "Epoch [35/50], Test Loss: 2.0236\n",
      "Test Accuracy: 43.35 %\n",
      "Epoch [36/50], Step [1/1000], Loss: 1.9173\n",
      "Epoch [36/50], Step [101/1000], Loss: 2.1333\n",
      "Epoch [36/50], Step [201/1000], Loss: 2.1300\n",
      "Epoch [36/50], Step [301/1000], Loss: 1.9965\n",
      "Epoch [36/50], Step [401/1000], Loss: 2.0360\n",
      "Epoch [36/50], Step [501/1000], Loss: 1.9753\n",
      "Epoch [36/50], Step [601/1000], Loss: 2.0307\n",
      "Epoch [36/50], Step [701/1000], Loss: 2.1084\n",
      "Epoch [36/50], Step [801/1000], Loss: 1.9163\n",
      "Epoch [36/50], Step [901/1000], Loss: 2.0918\n",
      "Epoch [36/50], Train Loss: 2.0170\n",
      "Epoch [36/50], Test Loss: 2.0234\n",
      "Test Accuracy: 43.43 %\n",
      "Epoch [37/50], Step [1/1000], Loss: 1.9786\n",
      "Epoch [37/50], Step [101/1000], Loss: 2.0474\n",
      "Epoch [37/50], Step [201/1000], Loss: 1.9889\n",
      "Epoch [37/50], Step [301/1000], Loss: 1.9703\n",
      "Epoch [37/50], Step [401/1000], Loss: 1.8877\n",
      "Epoch [37/50], Step [501/1000], Loss: 1.9515\n",
      "Epoch [37/50], Step [601/1000], Loss: 2.0169\n",
      "Epoch [37/50], Step [701/1000], Loss: 1.9639\n",
      "Epoch [37/50], Step [801/1000], Loss: 1.9279\n",
      "Epoch [37/50], Step [901/1000], Loss: 1.8643\n",
      "Epoch [37/50], Train Loss: 2.0123\n",
      "Epoch [37/50], Test Loss: 2.0344\n",
      "Test Accuracy: 42.48 %\n",
      "Epoch [38/50], Step [1/1000], Loss: 2.1389\n",
      "Epoch [38/50], Step [101/1000], Loss: 2.0213\n",
      "Epoch [38/50], Step [201/1000], Loss: 2.0102\n",
      "Epoch [38/50], Step [301/1000], Loss: 2.0458\n",
      "Epoch [38/50], Step [401/1000], Loss: 2.1863\n",
      "Epoch [38/50], Step [501/1000], Loss: 2.0486\n",
      "Epoch [38/50], Step [601/1000], Loss: 2.0286\n",
      "Epoch [38/50], Step [701/1000], Loss: 2.0874\n",
      "Epoch [38/50], Step [801/1000], Loss: 2.1407\n",
      "Epoch [38/50], Step [901/1000], Loss: 1.9740\n",
      "Epoch [38/50], Train Loss: 2.0121\n",
      "Epoch [38/50], Test Loss: 2.0253\n",
      "Test Accuracy: 43.18 %\n",
      "Epoch [39/50], Step [1/1000], Loss: 2.0325\n",
      "Epoch [39/50], Step [101/1000], Loss: 1.9266\n",
      "Epoch [39/50], Step [201/1000], Loss: 2.0043\n",
      "Epoch [39/50], Step [301/1000], Loss: 2.0512\n",
      "Epoch [39/50], Step [401/1000], Loss: 1.9813\n",
      "Epoch [39/50], Step [501/1000], Loss: 2.1173\n",
      "Epoch [39/50], Step [601/1000], Loss: 1.9772\n",
      "Epoch [39/50], Step [701/1000], Loss: 1.9672\n",
      "Epoch [39/50], Step [801/1000], Loss: 2.0684\n",
      "Epoch [39/50], Step [901/1000], Loss: 1.9547\n",
      "Epoch [39/50], Train Loss: 2.0099\n",
      "Epoch [39/50], Test Loss: 2.0213\n",
      "Test Accuracy: 43.79 %\n",
      "Epoch [40/50], Step [1/1000], Loss: 2.0444\n",
      "Epoch [40/50], Step [101/1000], Loss: 2.1081\n",
      "Epoch [40/50], Step [201/1000], Loss: 1.9832\n",
      "Epoch [40/50], Step [301/1000], Loss: 2.0934\n",
      "Epoch [40/50], Step [401/1000], Loss: 1.9801\n",
      "Epoch [40/50], Step [501/1000], Loss: 1.9290\n",
      "Epoch [40/50], Step [601/1000], Loss: 2.0801\n",
      "Epoch [40/50], Step [701/1000], Loss: 1.9945\n",
      "Epoch [40/50], Step [801/1000], Loss: 2.0049\n",
      "Epoch [40/50], Step [901/1000], Loss: 2.0449\n",
      "Epoch [40/50], Train Loss: 2.0082\n",
      "Epoch [40/50], Test Loss: 2.0267\n",
      "Test Accuracy: 43.1 %\n",
      "Epoch [41/50], Step [1/1000], Loss: 1.9859\n",
      "Epoch [41/50], Step [101/1000], Loss: 2.1653\n",
      "Epoch [41/50], Step [201/1000], Loss: 2.0722\n",
      "Epoch [41/50], Step [301/1000], Loss: 2.0190\n",
      "Epoch [41/50], Step [401/1000], Loss: 1.9654\n",
      "Epoch [41/50], Step [501/1000], Loss: 2.1156\n",
      "Epoch [41/50], Step [601/1000], Loss: 2.1154\n",
      "Epoch [41/50], Step [701/1000], Loss: 2.0759\n",
      "Epoch [41/50], Step [801/1000], Loss: 1.9884\n",
      "Epoch [41/50], Step [901/1000], Loss: 2.0370\n",
      "Epoch [41/50], Train Loss: 2.0056\n",
      "Epoch [41/50], Test Loss: 2.0184\n",
      "Test Accuracy: 43.98 %\n",
      "Epoch [42/50], Step [1/1000], Loss: 1.8594\n",
      "Epoch [42/50], Step [101/1000], Loss: 2.0403\n",
      "Epoch [42/50], Step [201/1000], Loss: 2.0321\n",
      "Epoch [42/50], Step [301/1000], Loss: 1.9680\n",
      "Epoch [42/50], Step [401/1000], Loss: 1.9071\n",
      "Epoch [42/50], Step [501/1000], Loss: 2.0413\n",
      "Epoch [42/50], Step [601/1000], Loss: 2.1009\n",
      "Epoch [42/50], Step [701/1000], Loss: 2.0257\n",
      "Epoch [42/50], Step [801/1000], Loss: 2.1252\n",
      "Epoch [42/50], Step [901/1000], Loss: 1.9929\n",
      "Epoch [42/50], Train Loss: 2.0053\n",
      "Epoch [42/50], Test Loss: 2.0135\n",
      "Test Accuracy: 44.4 %\n",
      "Epoch [43/50], Step [1/1000], Loss: 1.9930\n",
      "Epoch [43/50], Step [101/1000], Loss: 1.9680\n",
      "Epoch [43/50], Step [201/1000], Loss: 2.0770\n",
      "Epoch [43/50], Step [301/1000], Loss: 2.0491\n",
      "Epoch [43/50], Step [401/1000], Loss: 2.0335\n",
      "Epoch [43/50], Step [501/1000], Loss: 2.0601\n",
      "Epoch [43/50], Step [601/1000], Loss: 2.0645\n",
      "Epoch [43/50], Step [701/1000], Loss: 1.9208\n",
      "Epoch [43/50], Step [801/1000], Loss: 1.9766\n",
      "Epoch [43/50], Step [901/1000], Loss: 1.9811\n",
      "Epoch [43/50], Train Loss: 2.0015\n",
      "Epoch [43/50], Test Loss: 2.0269\n",
      "Test Accuracy: 42.99 %\n",
      "Epoch [44/50], Step [1/1000], Loss: 2.0250\n",
      "Epoch [44/50], Step [101/1000], Loss: 2.1370\n",
      "Epoch [44/50], Step [201/1000], Loss: 1.8386\n",
      "Epoch [44/50], Step [301/1000], Loss: 2.0455\n",
      "Epoch [44/50], Step [401/1000], Loss: 1.9902\n",
      "Epoch [44/50], Step [501/1000], Loss: 1.9298\n",
      "Epoch [44/50], Step [601/1000], Loss: 2.0544\n",
      "Epoch [44/50], Step [701/1000], Loss: 2.0655\n",
      "Epoch [44/50], Step [801/1000], Loss: 2.0098\n",
      "Epoch [44/50], Step [901/1000], Loss: 2.0488\n",
      "Epoch [44/50], Train Loss: 1.9991\n",
      "Epoch [44/50], Test Loss: 2.0247\n",
      "Test Accuracy: 43.49 %\n",
      "Epoch [45/50], Step [1/1000], Loss: 1.9216\n",
      "Epoch [45/50], Step [101/1000], Loss: 1.9333\n",
      "Epoch [45/50], Step [201/1000], Loss: 2.0107\n",
      "Epoch [45/50], Step [301/1000], Loss: 1.9934\n",
      "Epoch [45/50], Step [401/1000], Loss: 2.0049\n",
      "Epoch [45/50], Step [501/1000], Loss: 2.0199\n",
      "Epoch [45/50], Step [601/1000], Loss: 1.9446\n",
      "Epoch [45/50], Step [701/1000], Loss: 1.9046\n",
      "Epoch [45/50], Step [801/1000], Loss: 2.0560\n",
      "Epoch [45/50], Step [901/1000], Loss: 1.8846\n",
      "Epoch [45/50], Train Loss: 1.9984\n",
      "Epoch [45/50], Test Loss: 2.0112\n",
      "Test Accuracy: 44.63 %\n",
      "Epoch [46/50], Step [1/1000], Loss: 2.0213\n",
      "Epoch [46/50], Step [101/1000], Loss: 2.0750\n",
      "Epoch [46/50], Step [201/1000], Loss: 2.0022\n",
      "Epoch [46/50], Step [301/1000], Loss: 2.0377\n",
      "Epoch [46/50], Step [401/1000], Loss: 1.8986\n",
      "Epoch [46/50], Step [501/1000], Loss: 1.9992\n",
      "Epoch [46/50], Step [601/1000], Loss: 2.0014\n",
      "Epoch [46/50], Step [701/1000], Loss: 1.9067\n",
      "Epoch [46/50], Step [801/1000], Loss: 2.1303\n",
      "Epoch [46/50], Step [901/1000], Loss: 1.9961\n",
      "Epoch [46/50], Train Loss: 1.9951\n",
      "Epoch [46/50], Test Loss: 2.0172\n",
      "Test Accuracy: 44.03 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [1/1000], Loss: 1.8749\n",
      "Epoch [47/50], Step [101/1000], Loss: 2.0007\n",
      "Epoch [47/50], Step [201/1000], Loss: 1.9621\n",
      "Epoch [47/50], Step [301/1000], Loss: 1.9503\n",
      "Epoch [47/50], Step [401/1000], Loss: 1.9697\n",
      "Epoch [47/50], Step [501/1000], Loss: 1.9195\n",
      "Epoch [47/50], Step [601/1000], Loss: 1.9514\n",
      "Epoch [47/50], Step [701/1000], Loss: 2.0077\n",
      "Epoch [47/50], Step [801/1000], Loss: 1.9448\n",
      "Epoch [47/50], Step [901/1000], Loss: 1.9763\n",
      "Epoch [47/50], Train Loss: 1.9939\n",
      "Epoch [47/50], Test Loss: 2.0197\n",
      "Test Accuracy: 43.89 %\n",
      "Epoch [48/50], Step [1/1000], Loss: 2.0283\n",
      "Epoch [48/50], Step [101/1000], Loss: 2.0655\n",
      "Epoch [48/50], Step [201/1000], Loss: 2.0622\n",
      "Epoch [48/50], Step [301/1000], Loss: 2.0648\n",
      "Epoch [48/50], Step [401/1000], Loss: 1.9830\n",
      "Epoch [48/50], Step [501/1000], Loss: 2.0949\n",
      "Epoch [48/50], Step [601/1000], Loss: 1.9206\n",
      "Epoch [48/50], Step [701/1000], Loss: 1.9594\n",
      "Epoch [48/50], Step [801/1000], Loss: 1.9935\n",
      "Epoch [48/50], Step [901/1000], Loss: 1.9540\n",
      "Epoch [48/50], Train Loss: 1.9906\n",
      "Epoch [48/50], Test Loss: 2.0059\n",
      "Test Accuracy: 45.22 %\n",
      "Epoch [49/50], Step [1/1000], Loss: 1.9816\n",
      "Epoch [49/50], Step [101/1000], Loss: 1.9784\n",
      "Epoch [49/50], Step [201/1000], Loss: 1.9118\n",
      "Epoch [49/50], Step [301/1000], Loss: 2.0644\n",
      "Epoch [49/50], Step [401/1000], Loss: 2.0973\n",
      "Epoch [49/50], Step [501/1000], Loss: 1.8926\n",
      "Epoch [49/50], Step [601/1000], Loss: 1.9683\n",
      "Epoch [49/50], Step [701/1000], Loss: 1.9579\n",
      "Epoch [49/50], Step [801/1000], Loss: 1.9813\n",
      "Epoch [49/50], Step [901/1000], Loss: 2.0459\n",
      "Epoch [49/50], Train Loss: 1.9901\n",
      "Epoch [49/50], Test Loss: 1.9986\n",
      "Test Accuracy: 46.04 %\n",
      "Epoch [50/50], Step [1/1000], Loss: 2.0922\n",
      "Epoch [50/50], Step [101/1000], Loss: 1.9959\n",
      "Epoch [50/50], Step [201/1000], Loss: 1.8815\n",
      "Epoch [50/50], Step [301/1000], Loss: 1.9898\n",
      "Epoch [50/50], Step [401/1000], Loss: 2.0822\n",
      "Epoch [50/50], Step [501/1000], Loss: 1.9901\n",
      "Epoch [50/50], Step [601/1000], Loss: 1.9739\n",
      "Epoch [50/50], Step [701/1000], Loss: 1.9014\n",
      "Epoch [50/50], Step [801/1000], Loss: 2.0184\n",
      "Epoch [50/50], Step [901/1000], Loss: 1.9702\n",
      "Epoch [50/50], Train Loss: 1.9883\n",
      "Epoch [50/50], Test Loss: 2.0041\n",
      "Test Accuracy: 45.53 %\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "epochs = 50\n",
    "total_steps = len(trainloader)\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# loop through epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_running_loss = 0  # track train running loss\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # load batch images/labels\n",
    "    for step, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        # put data onto available device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = model(images)  # forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)  # retrieve top preds\n",
    "        \n",
    "        total += labels.size(0)  # add batch size\n",
    "        correct += (predicted == labels).sum().item()  # calc num correct\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # calc loss\n",
    "        train_running_loss += loss.item()  # acc running loss\n",
    "        \n",
    "        loss.backward()   # backprop\n",
    "        optimizer.step()  # forward\n",
    "\n",
    "        if step % 100 == 0:  # print progress by iteration\n",
    "        \n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "            .format(epoch+1, epochs, step+1, total_steps, loss.item()))\n",
    "    \n",
    "    # div by num batches to get average\n",
    "    epoch_train_loss = train_running_loss / len(trainloader)\n",
    "                   \n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, epochs, epoch_train_loss))\n",
    "        \n",
    "    # append the loss/acc after all the steps \n",
    "    training_losses.append(epoch_train_loss)\n",
    "    train_acc.append(correct / total)\n",
    "        \n",
    "    \n",
    "    # ------------------------------ #\n",
    "    \n",
    "\n",
    "    # evaluate on test data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_running_loss = 0  # track test running loss\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in testloader:\n",
    "                   \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "                   \n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()\n",
    "                   \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "                 \n",
    "    # div by num batches\n",
    "    epoch_test_loss = test_running_loss / len(testloader)\n",
    "                   \n",
    "    print('Epoch [{}/{}], Test Loss: {:.4f}'.format(epoch+1, epochs, epoch_test_loss))\n",
    "        \n",
    "    # append the loss & acc after all the steps \n",
    "    test_losses.append(epoch_test_loss)\n",
    "    test_acc.append(correct / total)\n",
    "            \n",
    "    print('Test Accuracy: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(train_losses, test_losses, train_acc, test_acc):\n",
    "    # plot graph\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Train loss\")\n",
    "    plt.plot(test_losses, label=\"Test loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss (Cross entropy)\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "    plt.plot(test_acc, label=\"Test Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Accuracy vs Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(training_losses, test_losses, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Network' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c3baa0f492f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Network' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Network' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ccb6b69e6ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Network' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
