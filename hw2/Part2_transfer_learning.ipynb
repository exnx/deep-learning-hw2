{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import imagenet_classes\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "model.eval()  # set in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the last 2 layers from classifier (fc, dropout)\n",
    "model.classifier = nn.Sequential(*[model.classifier[i] for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Dropout(p=0.5)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier  # check to see if removed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize features by their L2 norm\n",
    "def normalize_feat(x):\n",
    "    \n",
    "    # find the l2 norm per row (along columns), note detach, p is for l2\n",
    "    x_norm = torch.norm(x, p=2, dim=1).detach()\n",
    "    \n",
    "    # divide each elem by x_norm, note expand will match the same shape\n",
    "    x = x.div(x_norm.expand_as(x))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch dataset class\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        train_data = pd.read_csv(path_to_data, sep=\" \", header=None)\n",
    "        self.train_img_names = train_data.iloc[:,0]\n",
    "        self.train_img_labels = train_data.iloc[:,1]  # 1-37 species label\n",
    "        self.data_len = len(self.train_img_names)\n",
    "        self.size = (224, 224)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            image_dir = 'images'\n",
    "            single_image_name = self.train_img_names[index] + '.jpg'\n",
    "            img_path = os.path.join(image_dir, single_image_name)\n",
    "            \n",
    "            # Open image\n",
    "            img_as_img = Image.open(img_path).convert('RGB') # ensure 3 channels\n",
    "\n",
    "            label = int(self.train_img_labels[index])\n",
    "            \n",
    "#             print(type(label))\n",
    "\n",
    "            # Resize\n",
    "            resize = transforms.Resize(size=self.size)\n",
    "            img_as_img = resize(img_as_img)\n",
    "            \n",
    "            # Transform to tensor\n",
    "            toTensor = transforms.ToTensor()\n",
    "            img_as_tensor = toTensor(img_as_img)\n",
    "            \n",
    "            # normalize by ImageNet standards\n",
    "            normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            img_tensor_norm = normalize(img_as_tensor)\n",
    "            \n",
    "            return (img_tensor_norm, label)\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to train and test data\n",
    "train_data_path = 'annotations/trainval.txt'\n",
    "test_data_path = 'annotations/test.txt'\n",
    "\n",
    "# create dataset\n",
    "train_dataset = PetDataset(train_data_path)\n",
    "test_dataset = PetDataset(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3669"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "# obtain training data features and labels\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "# loop through dataloader\n",
    "for img_tensor, label in train_dataloader:\n",
    "    \n",
    "#     if count == 40:\n",
    "#         break\n",
    "    \n",
    "    # forward prop to get features\n",
    "    img_feat = model(img_tensor)\n",
    "    \n",
    "    # normalize features by L2, convert to list\n",
    "    img_feat = normalize_feat(img_feat).tolist()\n",
    "    \n",
    "    x_train.extend(img_feat)\n",
    "    y_train.extend(label.tolist())  # convert label to list too\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "# obtain training data features and labels\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "# loop through dataloader\n",
    "for img_tensor, label in test_dataloader:\n",
    "    \n",
    "#     if count == 30:\n",
    "#         break\n",
    "    \n",
    "    # forward prop to get features\n",
    "    img_feat = model(img_tensor)\n",
    "    \n",
    "    # normalize features by L2, convert to list\n",
    "    img_feat = normalize_feat(img_feat).tolist()\n",
    "    \n",
    "    x_test.extend(img_feat)\n",
    "    y_test.extend(label.tolist())  # convert label to list too\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 84,  7, ...,  0,  0,  0],\n",
       "       [ 0, 13, 61, ..., 17,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  7, 17, ..., 60,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 94,  0],\n",
       "       [ 0,  0,  0, ...,  0,  1, 94]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83673469, 0.84      , 0.61      , 0.9       , 0.95      ,\n",
       "       0.88      , 0.84      , 0.95454545, 0.91919192, 0.69      ,\n",
       "       0.89      , 0.87628866, 0.94      , 0.96      , 0.99      ,\n",
       "       0.96      , 0.98      , 1.        , 0.97979798, 0.98      ,\n",
       "       0.77      , 0.9       , 0.99      , 0.82      , 0.98      ,\n",
       "       0.97      , 0.75      , 0.81      , 0.99      , 1.        ,\n",
       "       0.98989899, 0.97      , 0.84      , 0.94      , 0.6741573 ,\n",
       "       0.94      , 0.94      ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per class accuracy\n",
    "cm.diagonal()/cm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986652702831485"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall accuracy\n",
    "np.average(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I used VGG19, which is on not as deep as state of the art models, but I figured\n",
    "I would start with a simpler, smaller model (in terms of layers) so that\n",
    "I could follow what was going on better.  It seemed to perform pretty well,\n",
    "with an overall accuracy of 0.90.  As for per class accuracy, there were 2\n",
    "classes in particular that didn't do well, which were class 3 and class 35, which\n",
    "had accuracies of 0.61 and 0.67, respectively.  These was the American\n",
    "Pit Bull, and the staffordshire_bull_terrier, which interestingly were \n",
    "both a type of bull dogs.  Perhaps between the two, the dogs look similar \n",
    "and can misclassify with each other.\n",
    "\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
